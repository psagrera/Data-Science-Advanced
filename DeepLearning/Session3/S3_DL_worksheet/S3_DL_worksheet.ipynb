{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mioti.png\" style=\"height: 100px\">\n",
    "<center style=\"color:#888\">Módulo Data Science in IoT<br/>Asignatura Deep Learning</center>\n",
    "\n",
    "# Worksheet S3: Redes Neuronales Profundas en Keras (DNNs)\n",
    "\n",
    "## Objetivos \n",
    "\n",
    "El objetivo de este worksheet es continuar comprendiendo las particularidades de las redes neuronales profundas (DNNs) mediante su implementación en Keras.\n",
    "\n",
    "## Keras\n",
    "\n",
    "Antes de meternos en el tema con profundidad vamos a echar un vistazo a keras.\n",
    "\n",
    "La documentación oficial, con el funcionamiento del código pormenorizado así como una buena batería de ejemplos podemos encontrarla aquí: https://keras.io/\n",
    "\n",
    "Keras es una API de redes neuronales de alto nivel, escrita en Python y puede utilizar como motor de entrenamiento TensorFlow, CNTK o Theano. Desde finales de 2019 keras está integrado de forma nativa en TensorFlow facilitando su uso y mejorando su soporte. Entre otras ventajas, keras destaca por:\n",
    "\n",
    "- Prototipado fácil y rápido, ya que es una librería sencilla, intuitiva y modular.\n",
    "- Soporta redes convolucionales y recurrentes, así como la convinación de ambas.\n",
    "- Puede correr tanto en CPU como en GPU\n",
    "- Nos evita tener que construir una red neuronal desde 0 y nos abstrae de la complejidad matemática subyacente.\n",
    "\n",
    "Vamos a por nuestra primera red en keras!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrescamos las DNNs\n",
    "\n",
    "Como sabemos, las redes son una combinación de operaciones matemáticas simples y funciones de activación. Una red neuronal está formada por una secuencia de capas por las que van pasando nuestros datos. Estas capas están formadas por neuronas. En las redes DNN, dense o perceptrón multicapa (distintas nomenclaturas) cada neurona recibe como entrada todas las neuronas de la capa anterior y está conectada con todas las neuronas de la capa posterior.\n",
    "\n",
    "La notación matemática de una neurona es la siguiente:\n",
    "\n",
    "> $Y =(\\sum_{i=0}^n w_i x_i) + b$\n",
    "\n",
    "> $w$ representa los pesos de cada conexión con la neurona \n",
    "\n",
    "> $x$ representa el valor de las neuronas de la capa anterior\n",
    "\n",
    "> $b$ es una constante, representa el bias \n",
    "\n",
    "> $n$ es el número de conexiónes\n",
    "\n",
    "> $Y$ es la salida de la neurona\n",
    "\n",
    "Esa ecuación no está aún completa, se nos olvida una parte crucial, la **función de activación**. Esta función es la que la neurona aplica a los datos y permite que la red realice transformaciones no lineales. La función completa sería la siguiente:\n",
    "\n",
    "$Y =F((\\sum_{i=0}^n w_i x_i) + b)$\n",
    "\n",
    "### Representación de una DNN completa\n",
    "\n",
    "<img src=\"NeuralNetwork.png\" style=\"height: 500px\">\n",
    "\n",
    "#### Datos\n",
    "\n",
    "Como sabemos, nuestros datos entran diréctamente (aunque a veces realizamos normalizaciones previamente) a la red neuronal. En el caso de DNNs como las que estamos viendo hasta ahora, la entrada debe ser un único vector de tipo numérico por cada muestra.\n",
    "\n",
    "#### Capas\n",
    "\n",
    "Las redes tiene 3 tipos de capas:\n",
    "\n",
    "- Capa de entrada: Es la capa que recibe nuestros datos tal cual se los pasamos.\n",
    "- Capa/s oculta/s: Estas capas realizan la transformación no lineal de nuestros datos. Suelen compartir la función de activación. En el caso de redes DNN, cada neurona de una capa está conectada a todas las neuronas de la capa posterior.\n",
    "- Capa de salida: Es la capa donde podemos ver el resultado que saca la red.\n",
    "\n",
    "#### Pesos\n",
    "\n",
    "Cada una de las conexiones de una neurona con otra es una conexión con un peso, es decir con una fuerza asociada a esta conexión. El dato que saca una neurona es multiplicado por este peso antes de llegar a la neurona a la que está conectado.\n",
    "\n",
    "#### Funciones de activación\n",
    "\n",
    "La función de activación es la función que cada neurona aplica a la suma total de sus entradas antes de llevarla a la salida. Normalmente son funciones no lineales, lo que nos permite añadir complejidad al modelo consiguiendo hacer mejores predicciones.\n",
    "\n",
    "Las funciones de activación más típicas son las siguientes:\n",
    "\n",
    "<img src=\"ActivationFunction.pbm\" style=\"height: 300px\">\n",
    "\n",
    "En la capa de salida, suele utilizarse una función lineal en el caso de regresión o una capa softmax en el caso de clasificación. Recordemos que la capa softmax fuerza a que todas las neuronas tengan un valor entre 0 y 1 sumen en total 1, de forma que podemos considerar las salidas de esta capa probabilidades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando el entorno\n",
    "\n",
    "Como siempre, comenzamos importando los módulos y librerías que vamos a necesitar para nuestra implementación.\n",
    "\n",
    "Importamos numpy y fijamos una semilla para que las inicializaciones aleatorias sean igual aunque lo ejecutemos varias veces. De esta forma, los experimentos siempre llevan a los mismos resultados y podemos reproducirlos y encontrar fallos más fácilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x  # sólo necesaria si estamos en colab\n",
    "#!pip install tensorflow\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Otras librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos las capas y modelos que vamos a necesitar para este worksheet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "# Capa Densa (DNN normal)\n",
    "# Capa Activation (funcion de activacion)\n",
    "# Capa Flatten (reshape - matriz de X dimensiones y lo pone en modo vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "En este ejemplo vamos a utilizar el Fashion MNIST Dataset. Este dataset está incluido en keras, facilitando su carga y uso.\n",
    "\n",
    "Fashion MNIST contiene 60.000 imagenes para entrenar y 10.000 imagenes para validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a echar un vistazo a esos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener un conjunto separado de validación, vamos a separar 10000 imágenes de train (las primeras, por ejemplo) para validación, con lo que nuestros conjuntos quedarán separados en train, validación y test.\n",
    "\n",
    "Podemos comprobar también que nuestro conjunto de validación tiene ejemplos de todas las clases y aproximadamente balanceados por clase para evitar que el porcentaje de aciertos esté sesgado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9\n",
      "Examples class = 0: 942\n",
      "Examples class = 1: 1027\n",
      "Examples class = 2: 1016\n",
      "Examples class = 3: 1019\n",
      "Examples class = 4: 974\n",
      "Examples class = 5: 989\n",
      "Examples class = 6: 1021\n",
      "Examples class = 7: 1022\n",
      "Examples class = 8: 990\n",
      "Examples class = 9: 1000\n",
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000] # Entrena los hiperparametros\n",
    "\n",
    "# Comprobación de selección de datos de validación - Que esta balanceado\n",
    "print(Y_valid.min(), Y_valid.max())\n",
    "for i in range(10):\n",
    "    print('Examples class = ' + str(i) + ': ' + str(np.sum(Y_valid==i)))\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora, a ver cómo es uno de nuestros píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0,23,23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST contiene imágenes de 28x28 en escala de grises, con cada valor entre 0 (totalmente negro) y 255 (totalmente blanco)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesando los datos para Keras\n",
    "\n",
    "En función de las redes que vayamos a utilizar necesitaremos que nuestros datos estén en un formato u otro. Por ejemplo, las redes convolucionales esperan imágenes en tamaño #canales x ancho x alto.\n",
    "\n",
    "En nuestro caso, vamos a utilizar redes neuronales feed-forward como en la sesión anterior, así que necesitaremos que la entrada sea de una sola dimensión. Para este tipo de transformaciones, utilizaremos la función reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para confirmar esta transformación, podemos imprimir las dimensiones del conjunto de entrenamiento de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, transformaremos los datos de entrada al tipo float32 y los transformaremos para estar en el rango [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_valid = X_valid / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de las etiquetas para Keras\n",
    "\n",
    "A continuación, vamos a ver en qué formato están las etiquetas que recibimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pasaba en la implementación en TensorFlow, esto supone un problema debido a la definición de la función de coste. Deberíamos tener un vector de 10 valores, uno para cada clase. Tal y como lo tenemos ahora, nuestras etiquetas están en un array unidimensional. Vamos a ver los primeros 10 ejemplos para ver qué formato tienen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 7 6 8 7 7 2 0 5 3]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, nuestras etiquetas son un vector con los valores de las clases de 0 a 9.\n",
    "\n",
    "Para convertirlas al formato esperado por la red, aunque esta conversión podría resolverse con funciones de numpy pero es engorroso, vamos a utilizar la herramienta to\\_categorical que hemos importado al principio que resuelve este problema por nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, num_classes=10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si ya está resuelto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solucionado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNNs en Keras\n",
    "\n",
    "### Definiendo el modelo\n",
    "\n",
    "Ahora que los datos están preparados vamos a crear nuestro modelo. Por suerte, Keras es mucho más sencillo que TensorFlow. Vamos a implementar una red neuronal feed-forward con 2 capas ocultas de tamaño 512 y activación ReLu y una capa softmax al final.\n",
    "\n",
    "En Keras esto se hace de la siguiente forma:\n",
    "\n",
    "Primero declaramos un modelo secuencial de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, añadimos las capas ocultas feed-forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podeis ver, añadir capas en Keras es muy sencillo, es como si construyésemos nuestro modelo con piezas de Lego. Una de las grandes ventajas de Keras es que nosotros sólo necesitamos especificar la arquitectura que queremos, y Keras maneja de forma automática los tamaños de entrada y salida de cada una de estas capas (salvo la primera, que necesita recibir de manera explícita el tamaño de entrada de nuestros datos mediante el parámetro _input_\\__shape_. \n",
    "\n",
    "Por último, añadimos la capa de salida de tipo softmax con 10 unidades, una por cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilando el modelo\n",
    "\n",
    "Una vez que hemos definido el modelo, el siguiente paso es compilarlo. Para ello, tenemos que especificar la función de coste que vamos a emplear y el optimizador con el que queremos que se entrene. De forma opcional, podemos añadir también distintas métricas, de forma que al entrenar el modelo nos dé feedback en tiempo de entrenamiento.\n",
    "\n",
    "En nuestro caso vamos a utilizar lo mismo que en el ejemplo anterior, entropía cruzada como función de coste y el optimizador Adam. Especificaremos la probabilidad de acierto como la métrica que utilizaremos para visualización del rendimiento en tiempo de entrnamiento.\n",
    "\n",
    "En Keras, esto se especifica de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "Una vez hemos compilado el modelo, tan sólo nos queda un paso más para entrenarlo. Para ello deberemos especificar qué datos se van a utilizar, el tamaño del batch y el número de épocas que vamos a ver los datos en tiempo de entrenamieno.\n",
    "\n",
    "La opción verbose indica si queremos que el entrenamiento imprima información por pantalla o no.\n",
    "\n",
    "Podemos añadir además nuestro conjunto de validación, para que nos muestre el rendimiento en dicho conjunto al finalizar cada época.\n",
    "\n",
    "En Keras la función que entrena el modelo se llama fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4995 - accuracy: 0.8210 - val_loss: 0.4011 - val_accuracy: 0.8601\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3581 - accuracy: 0.8690 - val_loss: 0.3418 - val_accuracy: 0.8774\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3250 - accuracy: 0.8804 - val_loss: 0.3309 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2992 - accuracy: 0.8893 - val_loss: 0.3269 - val_accuracy: 0.8823\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2836 - accuracy: 0.8935 - val_loss: 0.3166 - val_accuracy: 0.8831\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2609 - accuracy: 0.9022 - val_loss: 0.3003 - val_accuracy: 0.8898\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2543 - accuracy: 0.9039 - val_loss: 0.3266 - val_accuracy: 0.8838\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2364 - accuracy: 0.9103 - val_loss: 0.2971 - val_accuracy: 0.8925\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2273 - accuracy: 0.9135 - val_loss: 0.3057 - val_accuracy: 0.8908\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2198 - accuracy: 0.9162 - val_loss: 0.3036 - val_accuracy: 0.8943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1637a8190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así de fácil!\n",
    "\n",
    "Hay una serie de funciones que se llaman 'callback' que sirven para añadir un criterio de parada, guardar los pesos del modelo mientras se está entrenando, guardar logs de cada época de entrenamiento y otras cosas que pueden sernos útiles para el entrenamiento (y algunas de las cuales exploraremos en los challenges), pero como hemos visto Keras es muy sencillo de utilizar y potente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del modelo\n",
    "\n",
    "Ya hemos entrenado el modelo, ahora vamos a comprobar su rendimiento evaluándolo sobre los datos de test de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.425385445356369, 0.847599983215332]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función evaluate devuelve en primer lugar el valor de la función de coste y a continuación cada una de las métricas que han sido añadidas al compilar el modelo, en nuestro caso, el primer valor es la entropía cruzada y el segundo el porcentaje de acierto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen final, todo el código en un solo script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.5014 - accuracy: 0.8193 - val_loss: 0.3770 - val_accuracy: 0.8632\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3632 - accuracy: 0.8665 - val_loss: 0.3662 - val_accuracy: 0.8687\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.3234 - accuracy: 0.8812 - val_loss: 0.3293 - val_accuracy: 0.8786\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2961 - accuracy: 0.8904 - val_loss: 0.3576 - val_accuracy: 0.8684\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2837 - accuracy: 0.8949 - val_loss: 0.3355 - val_accuracy: 0.8782\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2628 - accuracy: 0.9015 - val_loss: 0.3189 - val_accuracy: 0.8841\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2502 - accuracy: 0.9065 - val_loss: 0.3004 - val_accuracy: 0.8932\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2384 - accuracy: 0.9104 - val_loss: 0.3028 - val_accuracy: 0.8897\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2271 - accuracy: 0.9142 - val_loss: 0.3066 - val_accuracy: 0.8913\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.2166 - accuracy: 0.9174 - val_loss: 0.3250 - val_accuracy: 0.8862\n",
      "[0.3750571012496948, 0.8743000030517578]\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x  # sólo necesaria si estamos en colab\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Otras librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importamos las capas y modelos que vamos a necesitar para este worksheet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# Import Fashion MNIST data\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist\n",
    "\n",
    "# Primeras 10000 imágenes, las utilizamos como validación\n",
    "X_valid = train_images[:10000]\n",
    "Y_valid = train_labels[:10000]\n",
    "\n",
    "X_train = train_images[10000:]\n",
    "Y_train = train_labels[10000:]\n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 28*28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255\n",
    "X_valid = X_valid / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, 10)\n",
    "Y_valid = keras.utils.to_categorical(Y_valid, 10)\n",
    "Y_test = keras.utils.to_categorical(Y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=128, epochs=10, verbose=1, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
